{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bd6cc4-8ddd-4200-bb63-bc1368acf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 29.97\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict, deque\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"yolov8n.pt\"\n",
    "VIDEO_PATH = \"cars.mp4\"\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "SCALE = 0.5\n",
    "FRAME_SKIP = 2  # Process every 2nd frame\n",
    "\n",
    "REAL_WORLD_WIDTH_METERS = 15.0\n",
    "REAL_WORLD_HEIGHT_METERS = 48.0\n",
    "\n",
    "STATIONARY_PIXEL_THRESHOLD = 3  # pixel threshold for stationary detection\n",
    "STATIONARY_RESET_THRESHOLD_FRAMES = 8\n",
    "SPEED_BUFFER_MAXLEN = 5\n",
    "\n",
    "SOURCE_POINTS_FILE = \"perspective_points.json\"\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "kalman_filters = {}\n",
    "track_history = defaultdict(list)\n",
    "speed_estimates = {}\n",
    "stationary_frames_count = defaultdict(int)\n",
    "speed_buffer = defaultdict(lambda: deque(maxlen=SPEED_BUFFER_MAXLEN))\n",
    "SOURCE_POINTS = None\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def create_kalman_filter():\n",
    "    kf = cv2.KalmanFilter(4, 2)\n",
    "    kf.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]], np.float32)\n",
    "    kf.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]], np.float32)\n",
    "    kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "    kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.5\n",
    "    kf.errorCovPost = np.eye(4, dtype=np.float32)\n",
    "    return kf\n",
    "\n",
    "def cleanup_stale_trackers(current_track_ids):\n",
    "    known_track_ids = set(kalman_filters.keys())\n",
    "    stale_ids = known_track_ids - set(current_track_ids)\n",
    "    for track_id in stale_ids:\n",
    "        del kalman_filters[track_id]\n",
    "        del track_history[track_id]\n",
    "        speed_estimates.pop(track_id, None)\n",
    "        stationary_frames_count.pop(track_id, None)\n",
    "        speed_buffer.pop(track_id, None)\n",
    "\n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(params['points']) < 4:\n",
    "        params['points'].append((x, y))\n",
    "        print(f\"Point {len(params['points'])} added: ({x}, {y})\")\n",
    "\n",
    "def get_perspective_transform_points(cap):\n",
    "    global SOURCE_POINTS\n",
    "    if os.path.exists(SOURCE_POINTS_FILE):\n",
    "        with open(SOURCE_POINTS_FILE, 'r') as f:\n",
    "            points = json.load(f)\n",
    "            SOURCE_POINTS = np.array(points, dtype=\"float32\")\n",
    "            return\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        raise SystemExit(\"Error: Could not read the first frame.\")\n",
    "\n",
    "    clone = frame.copy()\n",
    "    params = {'points': []}\n",
    "    cv2.namedWindow(\"Select 4 Points\")\n",
    "    cv2.setMouseCallback(\"Select 4 Points\", mouse_callback, params)\n",
    "    print(\"Select 4 points: Top-Left, Top-Right, Bottom-Right, Bottom-Left\")\n",
    "\n",
    "    while True:\n",
    "        temp = clone.copy()\n",
    "        for i, pt in enumerate(params['points']):\n",
    "            cv2.circle(temp, pt, 5, (0,255,0), -1)\n",
    "            cv2.putText(temp, str(i+1), (pt[0]+10, pt[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255),2)\n",
    "        cv2.imshow(\"Select 4 Points\", temp)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if len(params['points']) == 4 and (key == 13 or key == 32):\n",
    "            break\n",
    "        elif key == ord('r'):\n",
    "            params['points'] = []\n",
    "            print(\"Points reset. Select again.\")\n",
    "        elif key == ord('q'):\n",
    "            raise SystemExit(\"Calibration cancelled.\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    SOURCE_POINTS = np.array(params['points'], dtype=\"float32\")\n",
    "    with open(SOURCE_POINTS_FILE, 'w') as f:\n",
    "        json.dump(params['points'], f)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "def process_frame(frame, model, transform_matrix):\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_small = cv2.resize(frame, (int(w*SCALE), int(h*SCALE)))\n",
    "    results = model.track(frame_small, persist=True, classes=[2,3,5,7], conf=CONFIDENCE_THRESHOLD, verbose=False)\n",
    "    detections = []\n",
    "\n",
    "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x1, y1, x2, y2 = (box/SCALE).astype(int)\n",
    "            cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "            pt = np.array([[[cx, cy]]], dtype=\"float32\")\n",
    "            transformed_pt = cv2.perspectiveTransform(pt, transform_matrix)[0][0]\n",
    "            detections.append({\"box\": (x1,y1,x2,y2), \"track_id\": track_id, \"transformed_point\": transformed_pt})\n",
    "    return detections\n",
    "\n",
    "def update_tracker(detections, fps, pixels_per_meter):\n",
    "    stationary_threshold_m = STATIONARY_PIXEL_THRESHOLD / pixels_per_meter['y']\n",
    "\n",
    "    for det in detections:\n",
    "        tid = det['track_id']\n",
    "        point = det['transformed_point']\n",
    "\n",
    "        if tid not in kalman_filters:\n",
    "            kalman_filters[tid] = create_kalman_filter()\n",
    "        kf = kalman_filters[tid]\n",
    "        kf.predict()\n",
    "        kf.correct(np.array(point, dtype=np.float32))\n",
    "        track_history[tid].append(tuple(kf.statePost[:2].flatten()))\n",
    "\n",
    "        speed_kmh = 0.0\n",
    "        if len(track_history[tid]) > 1:\n",
    "            prev, curr = track_history[tid][-2], track_history[tid][-1]\n",
    "            dx = (curr[0] - prev[0]) / pixels_per_meter['x']\n",
    "            dy = (curr[1] - prev[1]) / pixels_per_meter['y']\n",
    "            meters_dist = np.sqrt(dx**2 + dy**2)\n",
    "            time_elapsed = FRAME_SKIP / fps\n",
    "\n",
    "            if meters_dist > stationary_threshold_m:\n",
    "                stationary_frames_count[tid] = 0\n",
    "                speed_kmh = meters_dist / time_elapsed * 3.6\n",
    "            else:\n",
    "                stationary_frames_count[tid] += 1\n",
    "                speed_kmh = 0\n",
    "\n",
    "        if stationary_frames_count[tid] >= STATIONARY_RESET_THRESHOLD_FRAMES:\n",
    "            speed_estimates[tid] = 0\n",
    "            speed_buffer[tid].clear()\n",
    "            track_history[tid].clear()\n",
    "            kf.statePost[2:] = 0\n",
    "        else:\n",
    "            speed_buffer[tid].append(speed_kmh)\n",
    "            speed_estimates[tid] = int(sum(speed_buffer[tid])/len(speed_buffer[tid])) if speed_buffer[tid] else 0\n",
    "\n",
    "def draw_annotations(frame, detections):\n",
    "    for det in detections:\n",
    "        x1,y1,x2,y2 = det['box']\n",
    "        tid = det['track_id']\n",
    "        speed = speed_estimates.get(tid, 0)\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        label = f\"ID {tid}\" if speed==0 else f\"ID {tid} | {speed} km/h\"\n",
    "        (w,h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "        cv2.rectangle(frame, (x1, y1-h-10), (x1+w, y1), (0,255,0), -1)\n",
    "        cv2.putText(frame, label, (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "    return frame\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        raise SystemExit(f\"Cannot open {VIDEO_PATH}\")\n",
    "\n",
    "    VIDEO_FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    print(f\"Video FPS: {VIDEO_FPS:.2f}\")\n",
    "\n",
    "    get_perspective_transform_points(cap)\n",
    "    dest_w = 800\n",
    "    dest_h = int(dest_w * (REAL_WORLD_HEIGHT_METERS/REAL_WORLD_WIDTH_METERS))\n",
    "    DEST_POINTS = np.float32([[0,0],[dest_w-1,0],[dest_w-1,dest_h-1],[0,dest_h-1]])\n",
    "    TRANSFORM_MATRIX = cv2.getPerspectiveTransform(SOURCE_POINTS, DEST_POINTS)\n",
    "    pixels_per_meter = {'x': dest_w/REAL_WORLD_WIDTH_METERS, 'y': dest_h/REAL_WORLD_HEIGHT_METERS}\n",
    "\n",
    "    frame_counter = 0\n",
    "    last_detections = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_counter += 1\n",
    "\n",
    "            if frame_counter % FRAME_SKIP == 0:\n",
    "                detections = process_frame(frame, model, TRANSFORM_MATRIX)\n",
    "                update_tracker(detections, VIDEO_FPS, pixels_per_meter)\n",
    "                current_ids = [d['track_id'] for d in detections]\n",
    "                cleanup_stale_trackers(current_ids)\n",
    "                last_detections = detections\n",
    "\n",
    "            annotated = draw_annotations(frame, last_detections)\n",
    "            cv2.polylines(annotated, [np.int32(SOURCE_POINTS)], True, (0,0,255),2)\n",
    "            cv2.imshow(\"Vehicle Speed Detection\", annotated)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a91ae-6252-4a11-9d64-de7fcfdb700c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
